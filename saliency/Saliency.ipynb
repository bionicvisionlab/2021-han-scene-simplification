{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Saliency.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zfCS1WaALA1h",
        "DHmI8qflpqp-",
        "RysFivFbfD8G"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4jixcFjRnA3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "787bfdf2-783e-45a2-fe23-5265d32f4d0d"
      },
      "source": [
        "# Mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02h8jE4M_LN9"
      },
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3vpHJK1DYbE"
      },
      "source": [
        "# import cv2\n",
        "# import os\n",
        "# vid_path = \"/content/gdrive/My Drive/291 Bionic Vision Project/Asa_Video/stim1_vid(done)\"\n",
        "# vidcap = cv2.VideoCapture('%s/stim1.mp4' % vid_path)\n",
        "# os.mkdir(\"%s/orig\" %(vid_path))\n",
        "# success,image = vidcap.read()\n",
        "# count = 0\n",
        "# while success:\n",
        "#   cv2.imwrite(\"%s/orig/frame_orig%d.jpg\" % (vid_path,count), image)     # save frame as JPEG file      \n",
        "#   success,image = vidcap.read()\n",
        "#   print('Read a new frame: ', success)\n",
        "#   count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHmI8qflpqp-"
      },
      "source": [
        "# mask RCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWOn9oJK-ABu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a3be928-a1fb-4dee-9e01-7a8417071898"
      },
      "source": [
        "# !pip install tensorflow==1.13.1\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAEsEpzkgxpq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62908ffd-7b7b-4ccc-d16f-147b38f73047"
      },
      "source": [
        "# !git clone https://github.com/matterport/Mask_RCNN.git\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/Mask_RCNN/samples/coco')\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "coco.py\t\t    inspect_model.ipynb    Mask_RCNN\tseg_1.png\n",
            "inspect_data.ipynb  inspect_weights.ipynb  __pycache__\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCddmroZSmHp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82474d93-5fff-46a6-e98f-2e3e2722c542"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import sys\n",
        "\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.axes as ax\n",
        "import json\n",
        "import skimage.io\n",
        "from skimage import measure\n",
        "from scipy.io import loadmat\n",
        "from scipy.spatial import distance\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"../../\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "from mrcnn import visualize\n",
        "from mrcnn.visualize import display_images\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn.model import log\n",
        "from mrcnn.utils import Dataset\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "# Path to Shapes trained weights\n",
        "SHAPES_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_shapes.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzb2w02eSr72"
      },
      "source": [
        "import coco\n",
        "config = coco.CocoConfig()\n",
        "COCO_DIR = \"/content/coco\" \n",
        "\n",
        "# Override the training configurations with a few\n",
        "# changes for inferencing.\n",
        "class InferenceConfig(config.__class__):\n",
        "    # Run detection on one image at a time\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "config = InferenceConfig()\n",
        "# config.display()\n",
        "\n",
        "\n",
        "# Device to load the neural network on.\n",
        "# Useful if you're training a model on the same \n",
        "# machine, in which case use CPU and leave the\n",
        "# GPU for training.\n",
        "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n",
        "\n",
        "# Inspect the model in training or inference modes\n",
        "# values: 'inference' or 'training'\n",
        "# TODO: code for 'training' test mode not ready yet\n",
        "TEST_MODE = \"inference\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VVgbMyBSx_7"
      },
      "source": [
        "def get_ax(rows=1, cols=1, size=16):\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\n",
        "    all visualizations in the notebook. Provide a\n",
        "    central point to control graph sizes.\n",
        "    \n",
        "    Adjust the size attribute to control how big to render images\n",
        "    \"\"\"\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KFbPKaCS0uK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebeca29f-81a2-46a4-ea17-7ddd0c039152"
      },
      "source": [
        "# Create model in inference mode\n",
        "with tf.device(DEVICE):\n",
        "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
        "                              config=config)\n",
        "\n",
        "# Set weights file path\n",
        "if config.NAME == \"shapes\":\n",
        "    weights_path = SHAPES_MODEL_PATH\n",
        "elif config.NAME == \"coco\":\n",
        "    weights_path = COCO_MODEL_PATH\n",
        "# Or, uncomment to load the last model you trained\n",
        "# weights_path = model.find_last()\n",
        "\n",
        "# Load weights\n",
        "print(\"Loading weights \", weights_path)\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "\n",
        "class_names =  ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/Mask_RCNN/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/Mask_RCNN/mrcnn/model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/Mask_RCNN/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/Mask_RCNN/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/Mask_RCNN/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "Loading weights  /content/gdrive/My Drive/Mask_RCNN/mask_rcnn_coco.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TBYKKjrpyUQ"
      },
      "source": [
        "# Deep Gaze II"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfZ4nZhrp0XF"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive')\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8UzrDaEp3wr"
      },
      "source": [
        "!git clone https://github.com/mpatacchiola/deepgaze.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuZy49pDqHGt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d567caf-5ef9-4cd0-8bd1-f0e327ceca1b"
      },
      "source": [
        "os.chdir(\"/content/gdrive/My Drive/deepgaze\")\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "debug.log  deepgaze  doc  etc  examples  LICENSE  README.md  setup.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa5BEdm7p-WJ"
      },
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "# The MIT License (MIT)\n",
        "# Copyright (c) 2017 Massimiliano Patacchiola\n",
        "# https://mpatacchiola.github.io\n",
        "# https://mpatacchiola.github.io/blog/\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
        "# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\n",
        "# CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n",
        "# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
        "\n",
        "# In this example the FASA algorithm is used in order to process some images.\n",
        "# The original image and the saliency version are showed for comparison.\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from timeit import default_timer as timer\n",
        "from deepgaze.saliency_map import FasaSaliencyMapping \n",
        "import os\n",
        "import glob\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.axes as ax\n",
        "import json\n",
        "import skimage.io\n",
        "from scipy.io import loadmat\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# def main():\n",
        "\n",
        "#     image_1 = cv2.imread(\"./horse.jpg\")\n",
        "#     image_2 = cv2.imread(\"./car.jpg\")\n",
        "#     image_3 = cv2.imread(\"./plane.jpg\")\n",
        "#     image_4 = cv2.imread(\"./pear.jpg\")\n",
        "\n",
        "#     # for each image the same operations are repeated\n",
        "#     my_map = FasaSaliencyMapping(image_1.shape[0], image_1.shape[1])  # init the saliency object\n",
        "#     start = timer()\n",
        "#     image_salient_1 = my_map.returnMask(image_1, tot_bins=8, format='BGR2LAB')  # get the mask from the original image\n",
        "#     image_salient_1 = cv2.GaussianBlur(image_salient_1, (3,3), 1)  # applying gaussin blur to make it pretty\n",
        "#     end = timer()\n",
        "#     print(\"--- %s Image 1 tot seconds ---\" % (end - start))\n",
        "\n",
        "#     my_map = FasaSaliencyMapping(image_2.shape[0], image_2.shape[1])\n",
        "#     start = timer()\n",
        "#     image_salient_2 = my_map.returnMask(image_2, tot_bins=8, format='BGR2LAB')\n",
        "#     image_salient_2 = cv2.GaussianBlur(image_salient_2, (3,3), 1)\n",
        "#     end = timer()\n",
        "#     print(\"--- %s Image 2 tot seconds ---\" % (end - start))\n",
        "\n",
        "#     my_map = FasaSaliencyMapping(image_3.shape[0], image_3.shape[1])\n",
        "#     start = timer()\n",
        "#     image_salient_3 = my_map.returnMask(image_3, tot_bins=8, format='BGR2LAB')\n",
        "#     #image_salient_3 = cv2.GaussianBlur(image_salient_3, (3,3), 1)\n",
        "#     end = timer()\n",
        "#     print(\"--- %s Image 3 tot seconds ---\" % (end - start))\n",
        "\n",
        "#     my_map = FasaSaliencyMapping(image_4.shape[0], image_4.shape[1])\n",
        "#     start = timer()\n",
        "#     image_salient_4 = my_map.returnMask(image_4, tot_bins=8, format='BGR2LAB')\n",
        "#     image_salient_4 = cv2.GaussianBlur(image_salient_4, (3,3), 1)\n",
        "#     end = timer()\n",
        "#     print(\"--- %s Image 4 tot seconds ---\" % (end - start))\n",
        "\n",
        "#     # Creating stack of images and showing them on screen\n",
        "#     original_images_stack = np.hstack((image_1, image_2, image_3, image_4))\n",
        "#     saliency_images_stack = np.hstack((image_salient_1, image_salient_2, image_salient_3, image_salient_4))\n",
        "#     saliency_images_stack = np.dstack((saliency_images_stack,saliency_images_stack,saliency_images_stack))\n",
        "#     cv2.imshow(\"Original-Saliency\", np.vstack((original_images_stack, saliency_images_stack)))\n",
        "\n",
        "#     while True:\n",
        "#         if cv2.waitKey(33) == ord('q'):\n",
        "#             cv2.destroyAllWindows()\n",
        "#             break\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMq2WSdemMOA"
      },
      "source": [
        "from skimage import feature\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RysFivFbfD8G"
      },
      "source": [
        "### functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y0aF9OXfDgs"
      },
      "source": [
        "def sal_mask(image):\n",
        "  '''\n",
        "  PARAMETERS:\n",
        "    image: input image [h, w, 3]\n",
        "  \n",
        "  RETURN:\n",
        "    origs: original images [h, w, 3, #images]\n",
        "    origs_gray: original images in grayscale [h, w, #images]\n",
        "    saliens: deepgaze saliency map of images [h, w, #images]\n",
        "    masks: combined object masks of images [h, w, #images]\n",
        "  '''\n",
        "  h,w,_ = image.shape\n",
        "\n",
        "  # get masks\n",
        "  results = model.detect([image])\n",
        "  r = results[0]\n",
        "  obj_masks = r[\"masks\"]\n",
        "  # fig = visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "  #                           class_names, r['scores'])\n",
        "\n",
        "  # get mask edges\n",
        "  num_objs = r[\"masks\"].shape[2]\n",
        "  obj_edges = np.zeros(r[\"masks\"].shape)\n",
        "  for o in range(num_objs):\n",
        "    m = r[\"masks\"][:,:,o]\n",
        "    edges = feature.canny(m, sigma=5).astype(\"uint8\")\n",
        "    kernel = np.ones((10,10), np.uint8) \n",
        "    edges_dilated = cv2.dilate(edges,kernel)\n",
        "    obj_edges[:,:,o] = edges_dilated\n",
        "\n",
        "  # # get all object masks into one mask\n",
        "  # combined_masks = np.sum(r['masks'],2)\n",
        "\n",
        "  # get saliency map\n",
        "  my_map = FasaSaliencyMapping(h, w) \n",
        "  image_salient = my_map.returnMask(image, tot_bins=8, format='BGR2LAB')  # get the mask from the original image\n",
        "  image_salient_blr = cv2.GaussianBlur(image_salient, (3,3), 1)\n",
        "\n",
        "  return image_salient_blr, obj_masks, r[\"rois\"], r[\"class_ids\"], obj_edges #roi top-left and bottom-right y,x\n",
        "\n",
        "\n",
        "def intersec_area(a, b):  # returns 0 if rectangles don't intersect\n",
        "    dx = np.min([a[3], b[3]]) - np.max([a[1], b[1]])\n",
        "    dy = np.mean([a[2], b[2]]) - np.max([a[0], b[0]])\n",
        "    if (dx>=0) and (dy>=0):\n",
        "        return dx*dy\n",
        "    else: \n",
        "      return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvWODZTwfJfy"
      },
      "source": [
        "### read original video and set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWWRslkigCIc"
      },
      "source": [
        "# vid_path = \"/content/gdrive/My Drive/291 Bionic Vision Project/Asa_Video/stim1_vid(done)\" # ORIGINAL VIDEO PATH FOLDER \n",
        "# vid_name = 'stim1.mp4'\n",
        "\n",
        "# cap = cv2.VideoCapture('%s/%s'% (vid_path, vid_name))\n",
        "\n",
        "# ret, frame1 = cap.read()\n",
        "\n",
        "# results = model.detect([frame1])\n",
        "# rs = results[0]\n",
        "# # fig = visualize.display_instances(frame1, rs['rois'], rs['masks'], rs['class_ids'], \n",
        "#                           # class_names, rs['scores'])\n",
        "\n",
        "\n",
        "# # set up optical flow \n",
        "# prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
        "# hsv = np.zeros_like(frame1)\n",
        "# hsv[...,1] = 255\n",
        "\n",
        "# # saliency observation window\n",
        "# W = 10\n",
        "# w_counter = 1\n",
        "# s, m, roi, ids, obj_edges = sal_mask(frame1)\n",
        "# s_history = np.copy(s)\n",
        "# s_history = np.expand_dims(s_history, axis=2)\n",
        "\n",
        "# roi_history = []\n",
        "# roi_history.append(roi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB4WdKs00pGE"
      },
      "source": [
        "# fig = visualize.display_instances(frame1, rs['rois'], rs['masks'], rs['class_ids'], \n",
        "#                           class_name?s, rs['scores'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_AzZuTy5nZq"
      },
      "source": [
        "### Segmentation (enhanced by optical flow) + Saliency (smoothied from previous frames and filted out large variance)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "472Gi1Dc9UiH"
      },
      "source": [
        "# importing the necessary libraries \n",
        "import cv2 \n",
        "import numpy as np \n",
        "\n",
        "# Creating a VideoCapture object to read the video \n",
        "cap = cv2.VideoCapture('sample.mp4') \n",
        "\n",
        "\n",
        "# Loop untill the end of the video \n",
        "while (cap.isOpened()): \n",
        "\n",
        "\t# Capture frame-by-frame \n",
        "\tret, frame = cap.read() \n",
        "\tframe = cv2.resize(frame, (540, 380), fx = 0, fy = 0, \n",
        "\t\t\t\t\t\tinterpolation = cv2.INTER_CUBIC) \n",
        "\n",
        "\t# Display the resulting frame \n",
        "\tcv2.imshow('Frame', frame) \n",
        "\n",
        "\t# conversion of BGR to grayscale is necessary to apply this operation \n",
        "\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
        "\n",
        "\t# adaptive thresholding to use different threshold \n",
        "\t# values on different regions of the frame. \n",
        "\tThresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
        "\t\t\t\t\t\t\t\t\t\tcv2.THRESH_BINARY_INV, 11, 2) \n",
        "\n",
        "\tcv2.imshow('Thresh', Thresh) \n",
        "\t# define q as the exit button \n",
        "\tif cv2.waitKey(25) & 0xFF == ord('q'): \n",
        "\t\tbreak\n",
        "\n",
        "# release the video capture object \n",
        "cap.release() \n",
        "# Closes all the windows currently opened. \n",
        "cv2.destroyAllWindows() \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dSlcwpZmC56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "309f2c26-2657-4c60-c04e-5218cc092a14"
      },
      "source": [
        "\n",
        "for idx in [1]:\n",
        "  print(\"processing video stim %d\" %idx)\n",
        "  frames=[]\n",
        "  vid_path = \"/content/gdrive/My Drive/291 Bionic Vision Project/Asa&Devi_Video/New Stimuli/Videos/stim%d_orig_frames\" %idx # ORIGINAL VIDEO PATH FOLDER \n",
        "  vid_name = 'stim%d.mp4' %idx\n",
        "\n",
        "  cap = cv2.VideoCapture('%s/%s'% (vid_path, vid_name))\n",
        "  ret, frame1 = cap.read()\n",
        "  #results = model.detect([frame1])\n",
        "  #rs = results[0]\n",
        "  # fig = visualize.display_instances(frame1, rs['rois'], rs['masks'], rs['class_ids'], \n",
        "                            # class_names, rs['scores'])\n",
        "\n",
        "\n",
        "  # set up optical flow \n",
        "  prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
        "  hsv = np.zeros_like(frame1)\n",
        "  hsv[...,1] = 255\n",
        "  abc=0\n",
        "  # saliency observation window\n",
        "  while (cap.isOpened()): \n",
        "\n",
        "    # Capture frame-by-frame \n",
        "    ret, frame = cap.read() \n",
        "    #frame = cv2.resize(frame, (540, 380), fx = 0, fy = 0, \n",
        "              #interpolation = cv2.INTER_CUBIC) \n",
        "\n",
        "    # Display the resulting frame \n",
        "    #cv2_imshow(frame) \n",
        "\n",
        "\n",
        "  ### create processed frames and downsampled frames ###\n",
        " \n",
        "    h,w,_ = frame.shape\n",
        "    my_map = FasaSaliencyMapping(h, w) \n",
        "\n",
        "    image_salient = my_map.returnMask(frame, tot_bins=8, format='BGR2LAB')  # get the mask from the original image\n",
        "    image_salient_blr = cv2.GaussianBlur(image_salient, (3,3), 1)\n",
        "    #cv2_imshow(image_salient_blr)\n",
        "    frames.append(image_salient_blr)\n",
        "    print(abc)\n",
        "    abc=abc+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing video stim 1\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-33b030120ac2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;31m### create processed frames and downsampled frames ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mmy_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFasaSaliencyMapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Appzr2s1Ewvz"
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive/saliency videos')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpIelgAHscAf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "583d31e6-eef5-4e32-ba82-9d9621d2c7cf"
      },
      "source": [
        "\n",
        "for idx in range(4,16):\n",
        "  print(\"processing video stim %d\" %idx)\n",
        "  frames=[]\n",
        "  vid_path = \"/content/gdrive/My Drive/291 Bionic Vision Project/Asa&Devi_Video/New Stimuli/Videos/stim%d_orig_frames\" %idx # ORIGINAL VIDEO PATH FOLDER \n",
        " \n",
        "    #frame = cv2.resize(frame, (540, 380), fx = 0, fy = 0, \n",
        "              #interpolation = cv2.INTER_CUBIC) \n",
        "\n",
        "    # Display the resulting frame \n",
        "    #cv2_imshow(frame) \n",
        "  os.chdir(vid_path)\n",
        "  for j in range(125):\n",
        "    fname=\"frame%d.jpg\" %(j+1)\n",
        "    ### create processed frames and downsampled frames ###\n",
        "    frame=cv2.imread(fname)\n",
        "    h,w,_ = frame.shape\n",
        "    my_map = FasaSaliencyMapping(h, w) \n",
        "\n",
        "    image_salient = my_map.returnMask(frame, tot_bins=8, format='BGR2LAB')  # get the mask from the original image\n",
        "    image_salient_blr = cv2.GaussianBlur(image_salient, (3,3), 1)\n",
        "    #cv2_imshow(image_salient_blr)\n",
        "    frames.append(image_salient_blr)\n",
        "    print(j)\n",
        "    \n",
        "\n",
        "  os.chdir('/content/gdrive/My Drive/saliency videos')\n",
        "  vidname=\"saliency_stim%d.avi\" %idx\n",
        "  out = cv2.VideoWriter(vidname, cv2.VideoWriter_fourcc(*'mp4v'), 20, (960, 540),isColor=False)\n",
        "  for i in range(125):\n",
        "    out.write(frames[i]) # frame is a numpy.ndarray with shape (1280, 720, 3)\n",
        "  out.release()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing video stim 4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "processing video stim 5\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "processing video stim 6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "processing video stim 7\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "processing video stim 8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "processing video stim 9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "processing video stim 10\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "processing video stim 11\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "processing video stim 12\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "processing video stim 13\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "processing video stim 14\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "processing video stim 15\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlum1ViwmB6X"
      },
      "source": [
        "## Combining saliency and segmentation using OR and then using them with depth\n",
        "for idx in [1]:\n",
        "  print(\"processing video stim %d\" %idx)\n",
        "  frames=[]\n",
        "  salvid_path = \"/content/gdrive/My Drive/291 Bionic Vision Project/Asa&Devi_Video/New Stimuli/saliency videos/\" # ORIGINAL VIDEO PATH FOLDER \n",
        "  salvid_name = 'stim%d.mp4' %idx\n",
        "\n",
        "  segvid_path = \"/content/gdrive/My Drive/291 Bionic Vision Project/Asa&Devi_Video/New Stimuli/segmentation videos/\" # ORIGINAL VIDEO PATH FOLDER \n",
        "  segvid_name = 'stim%d.mp4' %idx\n",
        "\n",
        "  depthvid_path = \"/content/gdrive/My Drive/291 Bionic Vision Project/Asa&Devi_Video/New Stimuli/depth videos/\" # ORIGINAL VIDEO PATH FOLDER \n",
        "  depthvid_name = 'stim%d.mp4' %idx\n",
        "\n",
        "\n",
        "\n",
        "  capsal = cv2.VideoCapture('%s/%s'% (salvid_path, salvid_name))\n",
        "  capseg = cv2.VideoCapture('%s/%s'% (segvid_path, segvid_name))\n",
        "  capdepth = cv2.VideoCapture('%s/%s'% (depthvid_path, depthvid_name))\n",
        "  #ret, frame1 = cap.read()\n",
        "  #results = model.detect([frame1])\n",
        "  #rs = results[0]\n",
        "  # fig = visualize.display_instances(frame1, rs['rois'], rs['masks'], rs['class_ids'], \n",
        "                            # class_names, rs['scores'])\n",
        "\n",
        "\n",
        "  # set up optical flow \n",
        "  \n",
        "  abc=0\n",
        "  # saliency observation window\n",
        "  while (abc<=123): \n",
        "\n",
        "    # Capture frame-by-frame \n",
        "    retsal, framesal = capsal.read() \n",
        "    retseg, frameseg = capseg.read() \n",
        "    retdepth, framedepth = capdepth.read() \n",
        "    #frame = cv2.resize(frame, (540, 380), fx = 0, fy = 0, \n",
        "              #interpolation = cv2.INTER_CUBIC) \n",
        "\n",
        "    # Display the resulting frame \n",
        "    cv2_imshow(framesal) \n",
        "    print(framesal.shape)\n",
        "\n",
        "  ### create processed frames and downsampled frames ###\n",
        "    #thresh_sal=\n",
        "\n",
        "    #frames.append(image_salient_blr)\n",
        "    print(abc)\n",
        "    abc=abc+1\n",
        "\n",
        " # os.chdir('/content/gdrive/My Drive/salsegdepth')\n",
        " # vidname=\"saliency_stim%d.avi\" %idx\n",
        " # out = cv2.VideoWriter(vidname, cv2.VideoWriter_fourcc(*'mp4v'), 20, (960, 540),isColor=False)\n",
        " # for i in range(125):\n",
        " #   out.write(frames[i]) # frame is a numpy.ndarray with shape (1280, 720, 3)\n",
        " # out.release()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}